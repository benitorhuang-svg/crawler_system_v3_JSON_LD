"""
å°ˆæ¡ˆåç¨±ï¼šcrawler_system_v3_JSON_LD
æ¨¡çµ„åç¨±ï¼šverify_checkpoint.py
åŠŸèƒ½æè¿°ï¼šæ–·é»çºŒçˆ¬ (Checkpoint) é©—è­‰å·¥å…·ï¼Œç¢ºä¿ç³»çµ±èƒ½æ­£ç¢ºè­˜åˆ¥ä¸¦è·³éç•¶æ—¥å·²å®Œæˆçš„è·ç¼ºåˆ†é¡ä»»å‹™ã€‚
ä¸»è¦å…¥å£ï¼špython test/scripts/verify_checkpoint.py
"""
import asyncio
import structlog
from datetime import datetime
from typing import Optional

from core.infra import Database, SourcePlatform, configure_logging
from core.services import CrawlService

# åˆå§‹åŒ–æ—¥èªŒ
configure_logging()
logger = structlog.get_logger(__name__)

async def verify_resume() -> None:
    """
    åŸ·è¡Œæ–·é»çºŒçˆ¬åŠŸèƒ½çš„ç«¯åˆ°ç«¯é©—è­‰ã€‚
    
    æµç¨‹ï¼š
    1. é¸å®šä¸€å€‹æ¸¬è©¦ç”¨åˆ†é¡ (104 å¹³å°)ã€‚
    2. æ‰‹å‹•åœ¨ tb_categories æ¨™è¨˜è©²åˆ†é¡ä»Šæ—¥å·²çˆ¬å–ã€‚
    3. å•Ÿå‹• CrawlService å˜—è©¦çˆ¬å–è©²åˆ†é¡ã€‚
    4. é©—è­‰æ˜¯å¦è§¸ç™¼ "category_skipped_checkpoint"ã€‚
    """
    db = Database()
    svc = CrawlService()
    
    # æ¸¬è©¦çµ„ä»¶
    platform: SourcePlatform = SourcePlatform.PLATFORM_104
    cat_id: str = "2003002019"
    
    print(f"\n--- [SDD] æ–·é»çºŒçˆ¬åŠŸèƒ½é©—è­‰å•Ÿå‹• ---")
    print(f"ğŸš€ å°‡ {platform.value}:{cat_id} æ¨™è¨˜ç‚ºä»Šæ—¥å·²å®Œæˆ...")
    
    try:
        # æ¨™è¨˜æ–·é»
        await db.mark_category_as_crawled(platform.value, cat_id)
        
        # åŸ·è¡Œçˆ¬å–
        print(f"ğŸš€ å•Ÿå‹•çˆ¬å–æ¸¬è©¦ï¼Œé æœŸæ­¤åˆ†é¡æ‡‰è¢«è·³é...")
        await svc.run_platform(platform, target_cat_id=cat_id, max_jobs=1)
        
        print("\nâœ… é©—è­‰æµç¨‹åŸ·è¡Œå®Œç•¢ï¼Œè«‹æª¢æŸ¥æ—¥èªŒè¼¸å‡ºæ˜¯å¦åŒ…å« 'category_skipped_checkpoint'ã€‚")
        
    except Exception as e:
        logger.error("verify_resume_failed", error=str(e))
        print(f"âŒ é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    finally:
        # å„ªé›…é—œé–‰è³‡æº
        await db.close_pool()
        await svc.db.close_pool()

if __name__ == "__main__":
    try:
        asyncio.run(verify_resume())
    except KeyboardInterrupt:
        pass
